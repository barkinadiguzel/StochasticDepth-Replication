# âš¡ StochasticDepth-Replication PyTorch Implementation

This repository contains a PyTorch replication of **ResNet with Stochastic Depth** including both **basic residual blocks** (for CIFAR) and **bottleneck blocks** (for ImageNet) for flexible deep network training.

- Implemented full **ResNet architecture with stochastic depth**.  
- Supports **CIFAR and ImageNet configurations** with linear decay of block survival probabilities during training.  
- Architecture follows:  
**Conv â†’ Residual/Bottleneck Stages â†’ AvgPool â†’ Flatten â†’ FC**  
**Paper:** [Deep Networks with Stochastic Depth](https://arxiv.org/abs/1603.09382)

---

## ğŸ–¼ Overview â€“ ResNet with Stochastic Depth

![Figure 1](images/figmixx.jpg)  

- **Figure 1:** A close-up of a single ResBlock in our ResNet with stochastic depth. Shows the internal flow: Convolution â†’ Batch Normalization â†’ ReLU â†’ Convolution â†’ Batch Normalization, plus the skip connection that either passes the input directly or projects it if dimensions differ. Highlights how stochastic depth may bypass this block during training.

- **Figure 2:** Illustration of the linear decay of survival probability across ResBlocks (from p0 = 1 to pL = 0.5). Conceptually, the input to the first ResBlock (H0) is always active. Later blocks have decreasing probability of being active, demonstrating how blocks may be skipped during training while the full network is used during testing.


- **General Model Idea:** Stochastic depth randomly drops blocks during training to reduce effective depth, improving gradient flow and speeding up training, but uses the full deep network during testing.

---

## ğŸ— Project Structure

```bash
StochasticDepth-Replication/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ layers/
â”‚   â”‚   â”œâ”€â”€ conv_layer.py            # BN â†’ ReLU â†’ Conv2d
â”‚   â”‚   â”œâ”€â”€ residual_block.py        # Normal residual block
â”‚   â”‚   â”œâ”€â”€ bottleneck_block.py      # Bottleneck residual block
â”‚   â”‚   â”œâ”€â”€ stochastic_depth.py      # Block drop logic
â”‚   â”‚   â””â”€â”€ shortcut_layer.py        # Skip connection logic (identity/projection)
â”‚   â”‚
â”‚   â”œâ”€â”€ blocks/
â”‚   â”‚   â”œâ”€â”€ basic_stage.py           # ResNet stage: several residual blocks
â”‚   â”‚   â””â”€â”€ full_resnet_stage.py     # Full combination of stages
â”‚   â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ resnet_cifar_sd.py       # CIFAR ResNet with stochastic depth
â”‚   â”‚   â””â”€â”€ resnet_imagenet_sd.py    # ImageNet ResNet with stochastic depth
â”‚   â”‚
â”‚   â””â”€â”€ config.py                    # Channels, block counts, survival probabilities
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---

## ğŸ”— Feedback

For questions or feedback, contact: [barkin.adiguzel@gmail.com](mailto:barkin.adiguzel@gmail.com)
